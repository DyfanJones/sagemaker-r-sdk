% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/amazon_factorization_machines.R
\name{FactorizationMachines}
\alias{FactorizationMachines}
\title{A supervised learning algorithm used in classification and regression.}
\description{
Factorization Machines combine the advantages of Support Vector Machines
             with factorization models. It is an extension of a linear model that is
             designed to capture interactions between features within high dimensional
             sparse datasets economically.
}
\section{Super classes}{
\code{\link[R6sagemaker:EstimatorBase]{R6sagemaker::EstimatorBase}} -> \code{\link[R6sagemaker:AmazonAlgorithmEstimatorBase]{R6sagemaker::AmazonAlgorithmEstimatorBase}} -> \code{FactorizationMachines}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{repo_name}}{sagemaker repo name for framework}

\item{\code{repo_version}}{version of framework}
}
\if{html}{\out{</div>}}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{num_factors}}{Dimensionality of factorization.}

\item{\code{predictor_type}}{Type of predictor 'binary_classifier' or 'regressor'.}

\item{\code{epochs}}{Number of training epochs to run.}

\item{\code{clip_gradient}}{Clip the gradient by projecting onto the box [-clip_gradient, +clip_gradient]}

\item{\code{eps}}{Small value to avoid division by 0.}

\item{\code{rescale_grad}}{If set, multiplies the gradient with rescale_grad before updating}

\item{\code{bias_lr}}{Non-negative learning rate for the bias term.}

\item{\code{linear_lr}}{Non-negative learning rate for linear terms.}

\item{\code{factors_lr}}{Non-negative learning rate for factorization terms.}

\item{\code{bias_wd}}{Non-negative weight decay for the bias term.}

\item{\code{linear_wd}}{Non-negative weight decay for linear terms.}

\item{\code{factors_wd}}{Non-negative weight decay for factorization terms.}

\item{\code{bias_init_method}}{Initialization method for the bias term:
'normal', 'uniform' or 'constant'.}

\item{\code{bias_init_scale}}{Non-negative range for initialization of
the bias term that takes effect when bias_init_method parameter
is 'uniform'}

\item{\code{bias_init_sigma}}{Non-negative standard deviation for
initialization of the bias term that takes effect when
bias_init_method parameter is 'normal'.}

\item{\code{bias_init_value}}{Initial value of the bias term that takes
effect when bias_init_method parameter is 'constant'.}

\item{\code{linear_init_method}}{Initialization method for linear term:
normal', 'uniform' or 'constant'.}

\item{\code{linear_init_scale}}{on-negative range for initialization of
linear terms that takes effect when linear_init_method parameter
is 'uniform'.}

\item{\code{linear_init_sigma}}{Non-negative standard deviation for
initialization of linear terms that takes effect when
linear_init_method parameter is 'normal'.}

\item{\code{linear_init_value}}{Initial value of linear terms that takes
effect when linear_init_method parameter is 'constant'.}

\item{\code{factors_init_method}}{Initialization method for
factorization term: 'normal', 'uniform' or 'constant'.}

\item{\code{factors_init_scale}}{Non-negative range for initialization of
factorization terms that takes effect when factors_init_method
parameter is 'uniform'.}

\item{\code{factors_init_sigma}}{Non-negative standard deviation for
initialization of factorization terms that takes effect when
factors_init_method parameter is 'normal'.}

\item{\code{factors_init_value}}{Initial value of factorization terms
that takes effect when factors_init_method parameter is
constant'.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{FactorizationMachines$new()}}
\item \href{#method-create_model}{\code{FactorizationMachines$create_model()}}
\item \href{#method-clone}{\code{FactorizationMachines$clone()}}
}
}
\if{html}{
\out{<details ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id=".prepare_for_training">}\href{../../R6sagemaker/html/EstimatorBase.html#method-.prepare_for_training}{\code{R6sagemaker::EstimatorBase$.prepare_for_training()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="attach">}\href{../../R6sagemaker/html/EstimatorBase.html#method-attach}{\code{R6sagemaker::EstimatorBase$attach()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="compile_model">}\href{../../R6sagemaker/html/EstimatorBase.html#method-compile_model}{\code{R6sagemaker::EstimatorBase$compile_model()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="delete_endpoint">}\href{../../R6sagemaker/html/EstimatorBase.html#method-delete_endpoint}{\code{R6sagemaker::EstimatorBase$delete_endpoint()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="deploy">}\href{../../R6sagemaker/html/EstimatorBase.html#method-deploy}{\code{R6sagemaker::EstimatorBase$deploy()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="disable_profiling">}\href{../../R6sagemaker/html/EstimatorBase.html#method-disable_profiling}{\code{R6sagemaker::EstimatorBase$disable_profiling()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="enable_default_profiling">}\href{../../R6sagemaker/html/EstimatorBase.html#method-enable_default_profiling}{\code{R6sagemaker::EstimatorBase$enable_default_profiling()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="enable_network_isolation">}\href{../../R6sagemaker/html/EstimatorBase.html#method-enable_network_isolation}{\code{R6sagemaker::EstimatorBase$enable_network_isolation()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="get_vpc_config">}\href{../../R6sagemaker/html/EstimatorBase.html#method-get_vpc_config}{\code{R6sagemaker::EstimatorBase$get_vpc_config()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="latest_job_debugger_artifacts_path">}\href{../../R6sagemaker/html/EstimatorBase.html#method-latest_job_debugger_artifacts_path}{\code{R6sagemaker::EstimatorBase$latest_job_debugger_artifacts_path()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="latest_job_profiler_artifacts_path">}\href{../../R6sagemaker/html/EstimatorBase.html#method-latest_job_profiler_artifacts_path}{\code{R6sagemaker::EstimatorBase$latest_job_profiler_artifacts_path()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="latest_job_tensorboard_artifacts_path">}\href{../../R6sagemaker/html/EstimatorBase.html#method-latest_job_tensorboard_artifacts_path}{\code{R6sagemaker::EstimatorBase$latest_job_tensorboard_artifacts_path()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="logs">}\href{../../R6sagemaker/html/EstimatorBase.html#method-logs}{\code{R6sagemaker::EstimatorBase$logs()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="print">}\href{../../R6sagemaker/html/EstimatorBase.html#method-print}{\code{R6sagemaker::EstimatorBase$print()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="register">}\href{../../R6sagemaker/html/EstimatorBase.html#method-register}{\code{R6sagemaker::EstimatorBase$register()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="transformer">}\href{../../R6sagemaker/html/EstimatorBase.html#method-transformer}{\code{R6sagemaker::EstimatorBase$transformer()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="EstimatorBase" data-id="update_profiler">}\href{../../R6sagemaker/html/EstimatorBase.html#method-update_profiler}{\code{R6sagemaker::EstimatorBase$update_profiler()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="AmazonAlgorithmEstimatorBase" data-id="fit">}\href{../../R6sagemaker/html/AmazonAlgorithmEstimatorBase.html#method-fit}{\code{R6sagemaker::AmazonAlgorithmEstimatorBase$fit()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="AmazonAlgorithmEstimatorBase" data-id="hyperparameters">}\href{../../R6sagemaker/html/AmazonAlgorithmEstimatorBase.html#method-hyperparameters}{\code{R6sagemaker::AmazonAlgorithmEstimatorBase$hyperparameters()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="AmazonAlgorithmEstimatorBase" data-id="prepare_workflow_for_training">}\href{../../R6sagemaker/html/AmazonAlgorithmEstimatorBase.html#method-prepare_workflow_for_training}{\code{R6sagemaker::AmazonAlgorithmEstimatorBase$prepare_workflow_for_training()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="AmazonAlgorithmEstimatorBase" data-id="record_set">}\href{../../R6sagemaker/html/AmazonAlgorithmEstimatorBase.html#method-record_set}{\code{R6sagemaker::AmazonAlgorithmEstimatorBase$record_set()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="AmazonAlgorithmEstimatorBase" data-id="training_image_uri">}\href{../../R6sagemaker/html/AmazonAlgorithmEstimatorBase.html#method-training_image_uri}{\code{R6sagemaker::AmazonAlgorithmEstimatorBase$training_image_uri()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="R6sagemaker" data-topic="AmazonAlgorithmEstimatorBase" data-id="wait">}\href{../../R6sagemaker/html/AmazonAlgorithmEstimatorBase.html#method-wait}{\code{R6sagemaker::AmazonAlgorithmEstimatorBase$wait()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Factorization Machines is :class:`Estimator` for general-purpose
             supervised learning.
             Amazon SageMaker Factorization Machines is a general-purpose
             supervised learning algorithm that you can use for both classification
             and regression tasks. It is an extension of a linear model that is
             designed to parsimoniously capture interactions between features within
             high dimensional sparse datasets.
             This Estimator may be fit via calls to
             :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.
             It requires Amazon :class:`~sagemaker.amazon.record_pb2.Record` protobuf
             serialized data to be stored in S3. There is an utility
             :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.record_set`
             that can be used to upload data to S3 and creates
             :class:`~sagemaker.amazon.amazon_estimator.RecordSet` to be passed to
             the `fit` call.
             To learn more about the Amazon protobuf Record class and how to
             prepare bulk data in this format, please consult AWS technical
             documentation:
             https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html
             After this Estimator is fit, model data is stored in S3. The model
             may be deployed to an Amazon SageMaker Endpoint by invoking
             :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as
             deploying an Endpoint, deploy returns a
             :class:`~sagemaker.amazon.pca.FactorizationMachinesPredictor` object
             that can be used for inference calls using the trained model hosted in
             the SageMaker Endpoint.
             FactorizationMachines Estimators can be configured by setting
             hyperparameters. The available hyperparameters for FactorizationMachines
             are documented below.
             For further information on the AWS FactorizationMachines algorithm,
             please consult AWS technical documentation:
             https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{FactorizationMachines$new(
  role,
  instance_count,
  instance_type,
  num_factors,
  predictor_type,
  epochs = NULL,
  clip_gradient = NULL,
  eps = NULL,
  rescale_grad = NULL,
  bias_lr = NULL,
  linear_lr = NULL,
  factors_lr = NULL,
  bias_wd = NULL,
  linear_wd = NULL,
  factors_wd = NULL,
  bias_init_method = NULL,
  bias_init_scale = NULL,
  bias_init_sigma = NULL,
  bias_init_value = NULL,
  linear_init_method = NULL,
  linear_init_scale = NULL,
  linear_init_sigma = NULL,
  linear_init_value = NULL,
  factors_init_method = NULL,
  factors_init_scale = NULL,
  factors_init_sigma = NULL,
  factors_init_value = NULL,
  ...
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{role}}{(str): An AWS IAM role (either name or full ARN). The Amazon
SageMaker training jobs and APIs that create Amazon SageMaker
endpoints use this role to access training data and model
artifacts. After the endpoint is created, the inference code
might use the IAM role, if accessing AWS resource.}

\item{\code{instance_count}}{(int): Number of Amazon EC2 instances to use
for training.}

\item{\code{instance_type}}{(str): Type of EC2 instance to use for training,
for example, 'ml.c4.xlarge'.}

\item{\code{num_factors}}{(int): Dimensionality of factorization.}

\item{\code{predictor_type}}{(str): Type of predictor 'binary_classifier' or
'regressor'.}

\item{\code{epochs}}{(int): Number of training epochs to run.}

\item{\code{clip_gradient}}{(float): Optimizer parameter. Clip the gradient by
projecting onto the box [-clip_gradient, +clip_gradient]}

\item{\code{eps}}{(float): Optimizer parameter. Small value to avoid division by
0.}

\item{\code{rescale_grad}}{(float): Optimizer parameter. If set, multiplies the
gradient with rescale_grad before updating. Often choose to be
1.0/batch_size.}

\item{\code{bias_lr}}{(float): Non-negative learning rate for the bias term.}

\item{\code{linear_lr}}{(float): Non-negative learning rate for linear terms.}

\item{\code{factors_lr}}{(float): Non-negative learning rate for factorization
terms.}

\item{\code{bias_wd}}{(float): Non-negative weight decay for the bias term.}

\item{\code{linear_wd}}{(float): Non-negative weight decay for linear terms.}

\item{\code{factors_wd}}{(float): Non-negative weight decay for factorization
terms.}

\item{\code{bias_init_method}}{(string): Initialization method for the bias term:
'normal', 'uniform' or 'constant'.}

\item{\code{bias_init_scale}}{(float): Non-negative range for initialization of
the bias term that takes effect when bias_init_method parameter
is 'uniform'}

\item{\code{bias_init_sigma}}{(float): Non-negative standard deviation for
initialization of the bias term that takes effect when
bias_init_method parameter is 'normal'.}

\item{\code{bias_init_value}}{(float): Initial value of the bias term that takes
effect when bias_init_method parameter is 'constant'.}

\item{\code{linear_init_method}}{(string): Initialization method for linear term:
'normal', 'uniform' or 'constant'.}

\item{\code{linear_init_scale}}{(float): Non-negative range for initialization of
linear terms that takes effect when linear_init_method parameter
is 'uniform'.}

\item{\code{linear_init_sigma}}{(float): Non-negative standard deviation for
initialization of linear terms that takes effect when
linear_init_method parameter is 'normal'.}

\item{\code{linear_init_value}}{(float): Initial value of linear terms that takes
effect when linear_init_method parameter is 'constant'.}

\item{\code{factors_init_method}}{(string): Initialization method for
factorization term: 'normal', 'uniform' or 'constant'.}

\item{\code{factors_init_scale}}{(float): Non-negative range for initialization of
factorization terms that takes effect when factors_init_method
parameter is 'uniform'.}

\item{\code{factors_init_sigma}}{(float): Non-negative standard deviation for
initialization of factorization terms that takes effect when
factors_init_method parameter is 'normal'.}

\item{\code{factors_init_value}}{(float): Initial value of factorization terms
that takes effect when factors_init_method parameter is
'constant'.}

\item{\code{...}}{: base class keyword argument values. You can find additional
parameters for initializing this class at
:class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and
:class:`~sagemaker.estimator.EstimatorBase`.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-create_model"></a>}}
\if{latex}{\out{\hypertarget{method-create_model}{}}}
\subsection{Method \code{create_model()}}{
Return a :class:`~sagemaker.amazon.FactorizationMachinesModel`
             referencing the latest s3 model data produced by this Estimator.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{FactorizationMachines$create_model(
  vpc_config_override = "VPC_CONFIG_DEFAULT",
  ...
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{vpc_config_override}}{(dict[str, list[str]]): Optional override for VpcConfig set on
the model. Default: use subnets and security groups from this Estimator.
* 'Subnets' (list[str]): List of subnet ids.
* 'SecurityGroupIds' (list[str]): List of security group ids.}

\item{\code{...}}{: Additional kwargs passed to the FactorizationMachinesModel constructor.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{FactorizationMachines$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
