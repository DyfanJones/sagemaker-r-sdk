% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pipeline.R
\name{PipeLineModel}
\alias{PipeLineModel}
\title{PipeLineModel Class}
\description{
A pipeline of SageMaker
             ``Model``s that can be deployed to an ``Endpoint``.
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{PipeLineModel$new()}}
\item \href{#method-pipeline_container_def}{\code{PipeLineModel$pipeline_container_def()}}
\item \href{#method-deploy}{\code{PipeLineModel$deploy()}}
\item \href{#method-transformer}{\code{PipeLineModel$transformer()}}
\item \href{#method-delete_model}{\code{PipeLineModel$delete_model()}}
\item \href{#method-clone}{\code{PipeLineModel$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Initialize an SageMaker ``Model`` which can be used to build an
             Inference Pipeline comprising of multiple model containers.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeLineModel$new(
  models,
  role,
  predictor_cls = NULL,
  name = NULL,
  vpc_config = NULL,
  sagemaker_session = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{models}}{(list[sagemaker.Model]): For using multiple containers to
build an inference pipeline, you can pass a list of ``sagemaker.Model`` objects
in the order you want the inference to happen.}

\item{\code{role}}{(str): An AWS IAM role (either name or full ARN). The Amazon
SageMaker training jobs and APIs that create Amazon SageMaker
endpoints use this role to access training data and model
artifacts. After the endpoint is created, the inference code
might use the IAM role, if it needs to access an AWS resource.}

\item{\code{predictor_cls}}{(callable[string, sagemaker.session.Session]): A
function to call to create a predictor (default: None). If not
None, ``deploy`` will return the result of invoking this
function on the created endpoint name.}

\item{\code{name}}{(str): The model name. If None, a default model name will be
selected on each ``deploy``.}

\item{\code{vpc_config}}{(dict[str, list[str]]): The VpcConfig set on the model
(default: None)
* 'Subnets' (list[str]): List of subnet ids.
* 'SecurityGroupIds' (list[str]): List of security group ids.}

\item{\code{sagemaker_session}}{(sagemaker.session.Session): A SageMaker Session
object, used for SageMaker interactions (default: None). If not
specified, one is created using the default AWS configuration
chain.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-pipeline_container_def"></a>}}
\if{latex}{\out{\hypertarget{method-pipeline_container_def}{}}}
\subsection{Method \code{pipeline_container_def()}}{
Return a dict created by ``sagemaker.pipeline_container_def()`` for
             deploying this model to a specified instance type.
             Subclasses can override this to provide custom container definitions
             for deployment to a specific instance type. Called by ``deploy()``.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeLineModel$pipeline_container_def(instance_type)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{instance_type}}{(str): The EC2 instance type to deploy this Model to.
For example, 'ml.p2.xlarge'.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
list[dict[str, str]]: A list of container definition objects usable
             with the CreateModel API in the scenario of multiple containers
             (Inference Pipeline).
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-deploy"></a>}}
\if{latex}{\out{\hypertarget{method-deploy}{}}}
\subsection{Method \code{deploy()}}{
Deploy this ``Model`` to an ``Endpoint`` and optionally return a
             ``Predictor``.
             Create a SageMaker ``Model`` and ``EndpointConfig``, and deploy an
             ``Endpoint`` from this ``Model``. If ``self.predictor_cls`` is not None,
             this method returns a the result of invoking ``self.predictor_cls`` on
             the created endpoint name.
             The name of the created model is accessible in the ``name`` field of
             this ``Model`` after deploy returns
             The name of the created endpoint is accessible in the
             ``endpoint_name`` field of this ``Model`` after deploy returns.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeLineModel$deploy(
  initial_instance_count,
  instance_type,
  endpoint_name = NULL,
  tags = NULL,
  wait = TRUE,
  update_endpoint = FALSE,
  data_capture_config = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{initial_instance_count}}{(int): The initial number of instances to run
in the ``Endpoint`` created from this ``Model``.}

\item{\code{instance_type}}{(str): The EC2 instance type to deploy this Model to.
For example, 'ml.p2.xlarge'.}

\item{\code{endpoint_name}}{(str): The name of the endpoint to create (default:
None). If not specified, a unique endpoint name will be created.}

\item{\code{tags}}{(List[dict[str, str]]): The list of tags to attach to this
specific endpoint.}

\item{\code{wait}}{(bool): Whether the call should wait until the deployment of
model completes (default: True).}

\item{\code{update_endpoint}}{(bool): Flag to update the model in an existing
Amazon SageMaker endpoint. If True, this will deploy a new
EndpointConfig to an already existing endpoint and delete
resources corresponding to the previous EndpointConfig. If
False, a new endpoint will be created. Default: False}

\item{\code{data_capture_config}}{(sagemaker.model_monitor.DataCaptureConfig): Specifies
configuration related to Endpoint data capture for use with
Amazon SageMaker Model Monitoring. Default: None.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
callable[string, sagemaker.session.Session] or None: Invocation of
             ``self.predictor_cls`` on the created endpoint name, if ``self.predictor_cls``
             is not None. Otherwise, return None.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-transformer"></a>}}
\if{latex}{\out{\hypertarget{method-transformer}{}}}
\subsection{Method \code{transformer()}}{
Return a ``Transformer`` that uses this Model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeLineModel$transformer(
  instance_count,
  instance_type,
  strategy = NULL,
  assemble_with = NULL,
  output_path = NULL,
  output_kms_key = NULL,
  accept = NULL,
  env = NULL,
  max_concurrent_transforms = NULL,
  max_payload = NULL,
  tags = NULL,
  volume_kms_key = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{instance_count}}{(int): Number of EC2 instances to use.}

\item{\code{instance_type}}{(str): Type of EC2 instance to use, for example,
ml.c4.xlarge'.}

\item{\code{strategy}}{(str): The strategy used to decide how to batch records in
a single request (default: None). Valid values: 'MultiRecord'
and 'SingleRecord'.}

\item{\code{assemble_with}}{(str): How the output is assembled (default: None).
Valid values: 'Line' or 'None'.}

\item{\code{output_path}}{(str): S3 location for saving the transform result. If
not specified, results are stored to a default bucket.}

\item{\code{output_kms_key}}{(str): Optional. KMS key ID for encrypting the
transform output (default: None).}

\item{\code{accept}}{(str): The accept header passed by the client to
the inference endpoint. If it is supported by the endpoint,
it will be the format of the batch transform output.}

\item{\code{env}}{(dict): Environment variables to be set for use during the
transform job (default: None).}

\item{\code{max_concurrent_transforms}}{(int): The maximum number of HTTP requests
to be made to each individual transform container at one time.}

\item{\code{max_payload}}{(int): Maximum size of the payload in a single HTTP
request to the container in MB.}

\item{\code{tags}}{(list[dict]): List of tags for labeling a transform job. If
none specified, then the tags used for the training job are used
for the transform job.}

\item{\code{volume_kms_key}}{(str): Optional. KMS key ID for encrypting the volume
attached to the ML compute instance (default: None).}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-delete_model"></a>}}
\if{latex}{\out{\hypertarget{method-delete_model}{}}}
\subsection{Method \code{delete_model()}}{
Delete the SageMaker model backing this pipeline model. This does not
             delete the list of SageMaker models used in multiple containers to build
             the inference pipeline.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeLineModel$delete_model()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeLineModel$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
